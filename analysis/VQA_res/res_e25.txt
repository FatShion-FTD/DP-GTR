
25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 37, 'do_sample': True, 'temperature': 1.50435456, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd637ae7e80>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.2724465368656923; rouge2 mean: 0.12718404868236052; rougeL mean: 0.24795613966078767
rouge1 std: 0.010722917791738123; rouge2 std: 0.007045215410027843; rougeL std: 0.010587779728223022
bleu mean: 0.061107570178860746
bleu std: 0.005475363247119243
Answer paraphrased S1:
rouge1 mean: 0.18153766352825682; rouge2 mean: 0.1015733306051241; rougeL mean: 0.18084372302356055
rouge1 std: 0.023502593402108325; rouge2 std: 0.019413354026912015; rougeL std: 0.02314976462065068
bleu mean: 0.047263180777076925
bleu std: 0.01065452140097165
S2 Question generated:
BLEU MEAN Question: 0.01510718028179423 STD Question: 0.00011431727035572951
ROUGE1 MEAN Question: 0.13341972843858346 STD Question: 0.00499666228287755
ROUGE2 MEAN Question: 0.029119869026834666 STD Question: 0.0021613963408340826
ROUGEL MEAN Question: 0.11422560857811619 STD Question: 0.004821359940699328
S2 Answer generated:
BLEU MEAN Answer: 0.02145590010638675 STD Answer: 0.003483883494742588
ROUGE1 MEAN Answer: 0.10108291382653338 STD Answer: 0.004336798301540091
ROUGE2 MEAN Answer: 0.06430932987547054 STD Answer: 0.002501952989210979
ROUGEL MEAN Answer: 0.10039857723597324 STD Answer: 0.004649656089599563

25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 1.14458432, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd623fbe850>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.5010052355573745; rouge2 mean: 0.40654728669993934; rougeL mean: 0.4808388140346638
rouge1 std: 0.017499601995264135; rouge2 std: 0.017683592014964212; rougeL std: 0.01652377160693076
bleu mean: 0.20056215238378058
bleu std: 0.013133534638336507
Answer paraphrased S1:
rouge1 mean: 0.3729594449337838; rouge2 mean: 0.2184993762740145; rougeL mean: 0.3718847553370564
rouge1 std: 0.025260259534024523; rouge2 std: 0.020759720479092535; rougeL std: 0.025373603984244444
bleu mean: 0.13176381461345613
bleu std: 0.021653652828278726
S2 Question generated:
BLEU MEAN Question: 0.03996445054858496 STD Question: 0.0024225701652111895
ROUGE1 MEAN Question: 0.19278202007099168 STD Question: 0.005441742925431674
ROUGE2 MEAN Question: 0.11742498040016204 STD Question: 0.006639544742426315
ROUGEL MEAN Question: 0.17526845180331274 STD Question: 0.005163625841089643
S2 Answer generated:
BLEU MEAN Answer: 0.032128601558162495 STD Answer: 0.0066182367443131974
ROUGE1 MEAN Answer: 0.1728384939445823 STD Answer: 0.023226619756903412
ROUGE2 MEAN Answer: 0.09335965621055098 STD Answer: 0.012192708522118019
ROUGEL MEAN Answer: 0.17095240568627013 STD Answer: 0.02245606601642166

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 47, 'do_sample': True, 'temperature': 1.50435456, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f96313ff520>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.2731177598348932; rouge2 mean: 0.12860287190171762; rougeL mean: 0.24746900795355148
rouge1 std: 0.009655408515242816; rouge2 std: 0.00929958079704954; rougeL std: 0.009077413545975977
bleu mean: 0.062936643097123
bleu std: 0.004170388105814632
Answer paraphrased S1:
rouge1 mean: 0.17765152786035648; rouge2 mean: 0.09789768736176999; rougeL mean: 0.1772479896480319
rouge1 std: 0.01467405277577643; rouge2 std: 0.013689750697105584; rougeL std: 0.014911278549105447
bleu mean: 0.04211247115162669
bleu std: 0.008126136932508818
S2 Question generated:
BLEU MEAN Question: 0.01662168907420859 STD Question: 0.001606373162277648
ROUGE1 MEAN Question: 0.1298062699678086 STD Question: 0.004157832659088356
ROUGE2 MEAN Question: 0.03279683070853328 STD Question: 0.0017703391960360668
ROUGEL MEAN Question: 0.1135430838068718 STD Question: 0.0028122411230033033
S2 Answer generated:
BLEU MEAN Answer: 0.014853505911324193 STD Answer: 0.005974106888694713
ROUGE1 MEAN Answer: 0.08869222720767878 STD Answer: 0.019209255560549556
ROUGE2 MEAN Answer: 0.04786325370436498 STD Answer: 0.019838183697990102
ROUGEL MEAN Answer: 0.08738571878557945 STD Answer: 0.018711965454410305

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 1.14458432, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f96244d9df0>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.48934752521420977; rouge2 mean: 0.39507921233972015; rougeL mean: 0.46915272918870093
rouge1 std: 0.0178182284165483; rouge2 std: 0.02109372775919788; rougeL std: 0.01847031980126414
bleu mean: 0.19074337246932335
bleu std: 0.013206628435749613
Answer paraphrased S1:
rouge1 mean: 0.36812025427865813; rouge2 mean: 0.2195280211672672; rougeL mean: 0.3678739846468218
rouge1 std: 0.024158105180172886; rouge2 std: 0.024054111275689783; rougeL std: 0.02429726463121344
bleu mean: 0.1189805191686875
bleu std: 0.017415328840208147
S2 Question generated:
BLEU MEAN Question: 0.0571568473295088 STD Question: 0.005837440386529143
ROUGE1 MEAN Question: 0.2519134695498495 STD Question: 0.0114433507121235
ROUGE2 MEAN Question: 0.15683343017144272 STD Question: 0.010726712500007925
ROUGEL MEAN Question: 0.23182905200233084 STD Question: 0.012100484935572066
S2 Answer generated:
BLEU MEAN Answer: 0.03938875472361933 STD Answer: 0.004684171108962957
ROUGE1 MEAN Answer: 0.17584602751881798 STD Answer: 0.010777805258578344
ROUGE2 MEAN Answer: 0.1087054275413543 STD Answer: 0.00762803692387746
ROUGEL MEAN Answer: 0.17464809388000938 STD Answer: 0.010512167149055679

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 0.7036176000000001, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc06d562ee0>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.3138276471817628; rouge2 mean: 0.1757204388879695; rougeL mean: 0.2899697976671191
rouge1 std: 0.01876294732614228; rouge2 std: 0.017063064643407268; rougeL std: 0.019587737293207504
bleu mean: 0.13160065859309247
bleu std: 0.014937813230350951
Answer paraphrased S1:
rouge1 mean: 0.1683094147070204; rouge2 mean: 0.0977401531071357; rougeL mean: 0.16770989535252087
rouge1 std: 0.017838174479959615; rouge2 std: 0.012301399807179871; rougeL std: 0.017129729623659978
bleu mean: 0.043362363946657406
bleu std: 0.010334025776153747
S2 Question generated:
BLEU MEAN Question: 0.0034237014839924355 STD Question: 0.0024953244972055516
ROUGE1 MEAN Question: 0.0497783955797275 STD Question: 0.008736151865036812
ROUGE2 MEAN Question: 0.011296808766917464 STD Question: 0.005540583903792351
ROUGEL MEAN Question: 0.04761150395466903 STD Question: 0.00803261398614658
S2 Answer generated:
BLEU MEAN Answer: 0.003044976014993065 STD Answer: 0.0009595343611423329
ROUGE1 MEAN Answer: 0.03204541345698845 STD Answer: 0.0036219446527467956
ROUGE2 MEAN Answer: 0.010161286843620191 STD Answer: 0.0021562248146184573
ROUGEL MEAN Answer: 0.030672767252860056 STD Answer: 0.0041709389441037985

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 1.1148816, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc067a1f070>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.25226148419876887; rouge2 mean: 0.10438793835393886; rougeL mean: 0.22739840284969978
rouge1 std: 0.013948829408277056; rouge2 std: 0.011885651927035916; rougeL std: 0.013524210520862397
bleu mean: 0.057901509601135555
bleu std: 0.007547681208971667
Answer paraphrased S1:
rouge1 mean: 0.15615734561212455; rouge2 mean: 0.0835895062209651; rougeL mean: 0.1554932677607113
rouge1 std: 0.019831773432614015; rouge2 std: 0.016032602531386143; rougeL std: 0.019943047205604462
bleu mean: 0.037139436456699274
bleu std: 0.008886852519301396
S2 Question generated:
BLEU MEAN Question: 0.00016591913123950653 STD Question: 0.00023464508565607163
ROUGE1 MEAN Question: 0.022675213020100848 STD Question: 0.0053213357600004185
ROUGE2 MEAN Question: 0.0038787958073672364 STD Question: 0.0012627207134418867
ROUGEL MEAN Question: 0.02149446890355691 STD Question: 0.0049629571928303615
S2 Answer generated:
BLEU MEAN Answer: 0.004373205879248193 STD Answer: 0.001712089115065033
ROUGE1 MEAN Answer: 0.04085371514594308 STD Answer: 0.0011170140732055817
ROUGE2 MEAN Answer: 0.017546819120973767 STD Answer: 0.0010435950153724134
ROUGEL MEAN Answer: 0.03947674240581906 STD Answer: 0.0011915824142315675

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 69, 'do_sample': True, 'temperature': 0.50708416, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc0679673d0>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.2275022715476169; rouge2 mean: 0.07734876190827225; rougeL mean: 0.21077210039638591
rouge1 std: 0.009024735036136215; rouge2 std: 0.005974318226410624; rougeL std: 0.008583223965658566
bleu mean: 0.030776878725089666
bleu std: 0.003128548003601922
Answer paraphrased S1:
rouge1 mean: 0.11038256014224285; rouge2 mean: 0.06124394876290315; rougeL mean: 0.10899775114844457
rouge1 std: 0.013807014255394922; rouge2 std: 0.012188899021864952; rougeL std: 0.013667789702356235
bleu mean: 0.024826555877631096
bleu std: 0.004994769473816042
S2 Question generated:
BLEU MEAN Question: 0.0045927097728076655 STD Question: 0.0033442426384094445
ROUGE1 MEAN Question: 0.07612245354588265 STD Question: 0.007341580762961503
ROUGE2 MEAN Question: 0.014759288171910476 STD Question: 0.005109643615279239
ROUGEL MEAN Question: 0.06948074106679519 STD Question: 0.00645209280100365
S2 Answer generated:
BLEU MEAN Answer: 0.005566514671971103 STD Answer: 0.002714067537433069
ROUGE1 MEAN Answer: 0.045877800366100556 STD Answer: 0.010355464685826113
ROUGE2 MEAN Answer: 0.019053638307171755 STD Answer: 0.0037433558684404097
ROUGEL MEAN Answer: 0.04444844088669624 STD Answer: 0.009508880950327335
