
25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 42, 'do_sample': True, 'temperature': 3.7608863999999995, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd600677670>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.06975278173974422; rouge2 mean: 0.00515664854518019; rougeL mean: 0.06108304016615184
rouge1 std: 0.006359326795672814; rouge2 std: 0.0014424043814624376; rougeL std: 0.005297962398560896
bleu mean: 0.0008900844456403014
bleu std: 0.001302967151425881
Answer paraphrased S1:
rouge1 mean: 0.037808326544008314; rouge2 mean: 0.019161899624846906; rougeL mean: 0.037494440532491374
rouge1 std: 0.006375493379979974; rouge2 std: 0.005803751836160113; rougeL std: 0.006422491698655082
bleu mean: 0.014824035666095558
bleu std: 0.0050012748916553485
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.041047160877770335 STD Question: 0.003003455951807961
ROUGE2 MEAN Question: 0.0007876487224877734 STD Question: 0.00043504847155502235
ROUGEL MEAN Question: 0.036289295996336894 STD Question: 0.002739448197551313
S2 Answer generated:
BLEU MEAN Answer: 0.0018926232487405756 STD Answer: 0.0013840140968379877
ROUGE1 MEAN Answer: 0.010682248353919205 STD Answer: 0.0017354354696433602
ROUGE2 MEAN Answer: 0.003152610790768685 STD Answer: 0.0020786385277106563
ROUGEL MEAN Answer: 0.010409897483710491 STD Answer: 0.0015856431096677598

25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 2.8614608000000006, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd623f11580>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.17867088953064034; rouge2 mean: 0.10076355213174285; rougeL mean: 0.1660164340852055
rouge1 std: 0.01078923586666142; rouge2 std: 0.005214194117290037; rougeL std: 0.008978652546351218
bleu mean: 0.07055776326395179
bleu std: 0.0021374341696774476
Answer paraphrased S1:
rouge1 mean: 0.16265129453754065; rouge2 mean: 0.10006193661594855; rougeL mean: 0.16141639227074775
rouge1 std: 0.014985658405164647; rouge2 std: 0.012354600596578256; rougeL std: 0.015244080472273155
bleu mean: 0.03974848968700729
bleu std: 0.006024253727352572
S2 Question generated:
BLEU MEAN Question: 0.009725645018431492 STD Question: 0.00022663506814314977
ROUGE1 MEAN Question: 0.041776439913418055 STD Question: 0.00356082105856756
ROUGE2 MEAN Question: 0.011287712220813595 STD Question: 0.0013301047355910457
ROUGEL MEAN Question: 0.03465038938665001 STD Question: 0.003490106676309625
S2 Answer generated:
BLEU MEAN Answer: 0.004472855324923083 STD Answer: 0.0017492795274531132
ROUGE1 MEAN Answer: 0.030162392228813117 STD Answer: 0.003751541560799425
ROUGE2 MEAN Answer: 0.01983869134458232 STD Answer: 0.0054382320831996445
ROUGEL MEAN Answer: 0.029468145531042808 STD Answer: 0.004285844368047399

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 67, 'do_sample': True, 'temperature': 3.7608863999999995, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f96578b7af0>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.06921778923744912; rouge2 mean: 0.005169535715034774; rougeL mean: 0.06076108498879094
rouge1 std: 0.005576720217381561; rouge2 std: 0.0015976961673381492; rougeL std: 0.0043611095858499755
bleu mean: 0.00039100935900851714
bleu std: 0.0008377505318688739
Answer paraphrased S1:
rouge1 mean: 0.03812907301097966; rouge2 mean: 0.019806732903196064; rougeL mean: 0.03809439269521401
rouge1 std: 0.010913224967387745; rouge2 std: 0.007880898004653233; rougeL std: 0.011073906148746128
bleu mean: 0.0160753658674178
bleu std: 0.004863485273897111
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.03943475876993988 STD Question: 0.003599270568371751
ROUGE2 MEAN Question: 0.0017503070773257107 STD Question: 0.000524594963307263
ROUGEL MEAN Question: 0.03480292837042716 STD Question: 0.0038854680154180423
S2 Answer generated:
BLEU MEAN Answer: 0.0065893673530235146 STD Answer: 0.0023728004996290495
ROUGE1 MEAN Answer: 0.02005891582724088 STD Answer: 0.007755471935231014
ROUGE2 MEAN Answer: 0.007187728461586942 STD Answer: 0.004406860977606374
ROUGEL MEAN Answer: 0.019403639341865342 STD Answer: 0.007688868407946935

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 2.8614608000000006, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f95859b1190>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.18197444283259873; rouge2 mean: 0.0995425255320403; rougeL mean: 0.16884397105438487
rouge1 std: 0.009539598230124695; rouge2 std: 0.005958204413202954; rougeL std: 0.008901215774142806
bleu mean: 0.07101585723627885
bleu std: 0.0034751385029265286
Answer paraphrased S1:
rouge1 mean: 0.16160226432114164; rouge2 mean: 0.09950601837206112; rougeL mean: 0.16091524421414977
rouge1 std: 0.019976505746986697; rouge2 std: 0.016058272746104385; rougeL std: 0.020381165754502353
bleu mean: 0.040334077419158794
bleu std: 0.005641756682514624
S2 Question generated:
BLEU MEAN Question: 0.0034676489081313113 STD Question: 0.0003631976087676966
ROUGE1 MEAN Question: 0.04462155399631335 STD Question: 0.002761075325618179
ROUGE2 MEAN Question: 0.004305460217487559 STD Question: 0.0009231268531698217
ROUGEL MEAN Question: 0.040316096129464914 STD Question: 0.002689372044206274
S2 Answer generated:
BLEU MEAN Answer: 0.013738546284809769 STD Answer: 0.0018194274919897406
ROUGE1 MEAN Answer: 0.03987745243491814 STD Answer: 0.0063479075650430886
ROUGE2 MEAN Answer: 0.0270331699440297 STD Answer: 0.007174116067520989
ROUGEL MEAN Answer: 0.03955013587467695 STD Answer: 0.006106968727602843

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 1.759044, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc05fe48100>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.13157639809195626; rouge2 mean: 0.015766568577476853; rougeL mean: 0.11252023164744553
rouge1 std: 0.006671818384511744; rouge2 std: 0.003044272604341343; rougeL std: 0.006205993069175878
bleu mean: 0.0017062673010489265
bleu std: 0.0028152244675134106
Answer paraphrased S1:
rouge1 mean: 0.050584755322779944; rouge2 mean: 0.02590195818342503; rougeL mean: 0.050165085875766804
rouge1 std: 0.0084164212574415; rouge2 std: 0.006966975355526032; rougeL std: 0.008112244914753175
bleu mean: 0.014585755190174816
bleu std: 0.005069551020118903
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.05615078787530664 STD Question: 0.0019373619237660759
ROUGE2 MEAN Question: 0.003997144649105434 STD Question: 0.000845327797899673
ROUGEL MEAN Question: 0.052192887603818156 STD Question: 0.0016486626541495474
S2 Answer generated:
BLEU MEAN Answer: 0.005684970330079748 STD Answer: 0.0008235533882505433
ROUGE1 MEAN Answer: 0.022381575973491774 STD Answer: 0.0023092141163379137
ROUGE2 MEAN Answer: 0.010443779597265937 STD Answer: 0.00431127011012507
ROUGEL MEAN Answer: 0.021770063657015642 STD Answer: 0.0022427566121210065

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 2.787204, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fbe84f453a0>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.12287941265909336; rouge2 mean: 0.011716619036027259; rougeL mean: 0.10283263323695507
rouge1 std: 0.007003711488541157; rouge2 std: 0.00199139391035121; rougeL std: 0.006185329600031465
bleu mean: 0.0002481528562900141
bleu std: 0.0007847282337528857
Answer paraphrased S1:
rouge1 mean: 0.07229316959590674; rouge2 mean: 0.036565241414734245; rougeL mean: 0.07155929438893581
rouge1 std: 0.011297621090986261; rouge2 std: 0.008264716590072666; rougeL std: 0.01153099082512287
bleu mean: 0.014132506810024002
bleu std: 0.0035463362516027484
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.049667667856833686 STD Question: 0.003403789814215784
ROUGE2 MEAN Question: 0.0010090528044248554 STD Question: 0.000687551466654431
ROUGEL MEAN Question: 0.04470292713286623 STD Question: 0.003955525104286531
S2 Answer generated:
BLEU MEAN Answer: 0.004411284867517803 STD Answer: 0.004035097640459453
ROUGE1 MEAN Answer: 0.017494946830675043 STD Answer: 0.005177017453136501
ROUGE2 MEAN Answer: 0.006256827934648691 STD Answer: 0.003328004293413891
ROUGEL MEAN Answer: 0.016140513136187255 STD Answer: 0.005374951172294508

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 35, 'do_sample': True, 'temperature': 1.2677104, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc0493817f0>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.10588384167475383; rouge2 mean: 0.009988623340249435; rougeL mean: 0.09512541019833778
rouge1 std: 0.006792890744337893; rouge2 std: 0.002316776409936822; rougeL std: 0.0061091454776346565
bleu mean: 0.0014542280081376604
bleu std: 0.0015948093363427223
Answer paraphrased S1:
rouge1 mean: 0.0321911844252655; rouge2 mean: 0.017001367702331818; rougeL mean: 0.0320326879182469
rouge1 std: 0.007360099872777284; rouge2 std: 0.006826314552423965; rougeL std: 0.007573297411354202
bleu mean: 0.009951169422158353
bleu std: 0.004601829221659601
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.05529832250138796 STD Question: 0.0014437029314572334
ROUGE2 MEAN Question: 0.004079495475813305 STD Question: 0.0007020487085153814
ROUGEL MEAN Question: 0.050095689480699666 STD Question: 0.0025086920409050934
S2 Answer generated:
BLEU MEAN Answer: 0.00663674960868611 STD Answer: 0.002312667036533383
ROUGE1 MEAN Answer: 0.025877338033376985 STD Answer: 0.00234844401998825
ROUGE2 MEAN Answer: 0.0125679580081754 STD Answer: 0.0018023070601865378
ROUGEL MEAN Answer: 0.025939289286118616 STD Answer: 0.0020464248407332172
