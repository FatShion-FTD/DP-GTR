{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Config: {'max_new_tokens': 100, 'do_sample': True, 'temperature': 1.0, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001}\n",
      "Clipped Config {'max_new_tokens': 100, 'do_sample': True, 'temperature': 2.8614608000000006, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f9a7cf310d0>]}\n",
      "Generated Text: Paraphrase the following question:\n",
      "A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\n",
      "Paraphrased Question:\n",
      "Two revolving doors allow passengers to enter on different doors; this system saves security and other cost. When a traveler chooses for one part, the whole system opens easily if an intrusions from exterior occurred, so there are\n",
      "Logits Length: 43, Token Length: 79, Input Length: 36\n"
     ]
    }
   ],
   "source": [
    "from dpps.SLM import SLM\n",
    "\n",
    "# Initialize the model\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tiny_llama = SLM(model_name)\n",
    "\n",
    "# Configure the generation\n",
    "tiny_llama.set_config(temperature=1.0, max_new_tokens=100)\n",
    "print(\"Current Config:\", tiny_llama.get_config())\n",
    "tiny_llama.clip_model(epsilon=10)\n",
    "print(f\"Clipped Config {tiny_llama.get_config()}\")\n",
    "\n",
    "# Input text\n",
    "input_text = \"Paraphrase the following question:\\nA revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\\nParaphrased Question:\\n\"\n",
    "pure_text = \"A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?\"\n",
    "\n",
    "# Generate text\n",
    "result = tiny_llama.generate(input_text, pure_text=pure_text)\n",
    "print(\"Generated Text:\", result[\"output_text\"])\n",
    "\n",
    "# Check logits\n",
    "all_logits = tiny_llama.check_logits(result[\"output_ids\"])\n",
    "all_selected_token_logits = tiny_llama.check_token_logits(result[\"output_ids\"])\n",
    "\n",
    "# Assertions and validation\n",
    "assert len(all_logits) == len(all_selected_token_logits)\n",
    "\n",
    "input_ids = tiny_llama.tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "input_length = input_ids.shape[-1]\n",
    "all_logits_length = len(all_logits)\n",
    "all_length = len(result[\"output_ids\"].sequences[0])\n",
    "\n",
    "print(f\"Logits Length: {all_logits_length}, Token Length: {all_length}, Input Length: {input_length}\")\n",
    "assert all_logits_length == all_length - input_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 8)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "data = load_dataset(\"nielsr/docvqa_1200_examples_donut\")\n",
    "train_df = data[\"train\"].to_pandas()\n",
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.22it/s]\n",
      "  0%|          | 0/1000 [00:00<?, ?it/s]From v4.47 onwards, when a model cache is to be returned, `generate` will return a `Cache` instance instead by default (as opposed to the legacy tuple of tuples format). If you want to keep returning the legacy format, please set `return_legacy_cache=True`.\n",
      "100%|██████████| 1000/1000 [1:12:54<00:00,  4.37s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1000,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     result \u001b[38;5;241m=\u001b[39m tiny_llama\u001b[38;5;241m.\u001b[39mgenerate(prompt)\n\u001b[1;32m     13\u001b[0m     all_logits\u001b[38;5;241m.\u001b[39mappend(tiny_llama\u001b[38;5;241m.\u001b[39mcheck_token_logits(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Logits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(all_logits)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Std Logits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(all_logits)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/lmc/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/lmc/lib/python3.9/site-packages/numpy/core/_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (1000,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "from dpps.SLM import SLM\n",
    "\n",
    "# Initialize the model\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "tiny_llama = SLM(model_name)\n",
    "all_logits = []\n",
    "for i, row in tqdm.tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "    input_text = row[\"query\"]['en']\n",
    "    prompt = \"Paraphrase the following question:\\n\" + input_text + \"\\nParaphrased Question:\\n\"\n",
    "    result = tiny_llama.generate(prompt)\n",
    "    \n",
    "    all_logits.append(tiny_llama.check_token_logits(result[\"output_ids\"]))\n",
    "    \n",
    "print(f\"Mean Logits: {np.mean(all_logits):.6f}, Std Logits: {np.std(all_logits):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Min: 14.819062, Total Max: 31.031375, Total Mean: 22.944258\n",
      "Total Min: 2.993405, Total Max: 6.170953, Total Mean: 2.420791\n"
     ]
    }
   ],
   "source": [
    "total_min, total_max, total_mean = [], [], []\n",
    "\n",
    "for logits_per_row in all_logits:\n",
    "    min_logits = np.min(logits_per_row)\n",
    "    max_logits = np.max(logits_per_row)\n",
    "    mean_logits = np.mean(logits_per_row)\n",
    "    total_min.append(min_logits)\n",
    "    total_max.append(max_logits)\n",
    "    total_mean.append(mean_logits)\n",
    "    \n",
    "print(f\"Total Min: {np.mean(total_min):.6f}, Total Max: {np.mean(total_max):.6f}, Total Mean: {np.mean(total_mean):.6f}\")\n",
    "print(f\"Total Min: {np.std(total_min):.6f}, Total Max: {np.std(total_max):.6f}, Total Mean: {np.std(total_mean):.6f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lmc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
