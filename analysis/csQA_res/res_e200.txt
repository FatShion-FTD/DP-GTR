
25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.18804432, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c8307f10>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.7999142832014283; rouge2 mean: 0.6844191832959152; rougeL mean: 0.739058577850293; rougeLSum mean: 0.74010530483605
rouge1 std: 0.00670421870182238; rouge2 std: 0.008324458180184945; rougeL std: 0.00708964565282903; rougeLSum std: 0.007262331382383723
bleu mean: 0.595845466436789
bleu std: 0.011217480224664048
Answer paraphrased S1:
Accuracy mean: 0.7663636363636364
S2 Question generated:
BLEU MEAN Question: 0.36373348396261657 STD Question: 0.01003563899811489
ROUGE1 MEAN Question: 0.6410798644128706 STD Question: 0.002270344136195427
ROUGE2 MEAN Question: 0.4797870861928389 STD Question: 0.0033223150875204836
ROUGEL MEAN Question: 0.5744326254964642 STD Question: 0.0025651454053988816
ROUGELSum MEAN Question: 0.573463065696049 STD Question: 0.0034817026170417416
S2 Answer generated:
Accuracy mean: 0.7333333333333334
Accuracy std: 0.020548046676563275
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.14307304, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c8307be0>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.9114480499666197; rouge2 mean: 0.9009711463326504; rougeL mean: 0.910292416647266; rougeLSum mean: 0.9104238432048248
rouge1 std: 0.0021173374025783144; rouge2 std: 0.0027125521386733064; rougeL std: 0.0022560552247544827; rougeLSum std: 0.002505167863904271
bleu mean: 0.7154186194161781
bleu std: 0.007285743953590706
Answer paraphrased S1:
Accuracy mean: 0.8118181818181818
S2 Question generated:
BLEU MEAN Question: 0.42339105680024547 STD Question: 0.004207793580742081
ROUGE1 MEAN Question: 0.7199544492838804 STD Question: 0.006544150937285057
ROUGE2 MEAN Question: 0.6994561130456433 STD Question: 0.005952099731689991
ROUGEL MEAN Question: 0.7178853097005661 STD Question: 0.006270940334455971
ROUGELSum MEAN Question: 0.7178970376884498 STD Question: 0.006605565433468529
S2 Answer generated:
Accuracy mean: 0.7866666666666666
Accuracy std: 0.02392116682401218
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.08795220000000001, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c81d8c40>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.49257303714751133; rouge2 mean: 0.4422591383658519; rougeL mean: 0.4830270845484646; rougeLSum mean: 0.48099260655353326
rouge1 std: 0.02594689857442065; rouge2 std: 0.026093085816435043; rougeL std: 0.025362973350566264; rougeLSum std: 0.02552089546952228
bleu mean: 0.3899914389926727
bleu std: 0.028224631508061128
Answer paraphrased S1:
Accuracy mean: 0.6459090909090909
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.0004347826086956523 STD Question: 0.0006148754619013458
ROUGE2 MEAN Question: 0.0 STD Question: 0.0
ROUGEL MEAN Question: 0.00028985507246376816 STD Question: 0.00040991697460089713
ROUGELSum MEAN Question: 0.00028985507246376816 STD Question: 0.00040991697460089713
S2 Answer generated:
Accuracy mean: 0.4966666666666666
Accuracy std: 0.008498365855987983
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.1393602, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c0b95640>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.6724933948988231; rouge2 mean: 0.5468776845870171; rougeL mean: 0.6437346835962505; rougeLSum mean: 0.6428817505859598
rouge1 std: 0.01008399827211164; rouge2 std: 0.013795988121627181; rougeL std: 0.011461222772128436; rougeLSum std: 0.011489674679992515
bleu mean: 0.4504684123675735
bleu std: 0.014344517587144662
Answer paraphrased S1:
Accuracy mean: 0.7231818181818181
S2 Question generated:
BLEU MEAN Question: 0.01297892672982831 STD Question: 0.003943630218621523
ROUGE1 MEAN Question: 0.11817901566416451 STD Question: 0.0011809553332111072
ROUGE2 MEAN Question: 0.06726025095379783 STD Question: 0.0011371008984364243
ROUGEL MEAN Question: 0.10738002852013405 STD Question: 0.0012669917176998697
ROUGELSum MEAN Question: 0.10691167985730025 STD Question: 0.001241054244310071
S2 Answer generated:
Accuracy mean: 0.5483333333333333
Accuracy std: 0.015456030825826136
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.06338552, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c8362f40>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.22588003567508066; rouge2 mean: 0.06210589992162871; rougeL mean: 0.18837518007512333; rougeLSum mean: 0.18822851463909226
rouge1 std: 0.008770380974056672; rouge2 std: 0.0056326707082958; rougeL std: 0.0066809436586042995; rougeLSum std: 0.006683351170402997
bleu mean: 0.025467384906633916
bleu std: 0.0036272304228920915
Answer paraphrased S1:
Accuracy mean: 0.6022727272727273
S2 Question generated:
BLEU MEAN Question: 0.008250850319918367 STD Question: 0.000441845635593155
ROUGE1 MEAN Question: 0.10080157961143632 STD Question: 0.0032532794736728045
ROUGE2 MEAN Question: 0.02085889810973623 STD Question: 0.000378413077201233
ROUGEL MEAN Question: 0.08465937381423001 STD Question: 0.004313733168782256
ROUGELSum MEAN Question: 0.08421016572001772 STD Question: 0.004492409200363032
S2 Answer generated:
Accuracy mean: 0.5466666666666667
Accuracy std: 0.011785113019775802
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.07289304000000002, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 151643, 'eos_token_id': 151643, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9b4168f10>]}
Qwen/Qwen2-1.5B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.4147619599229193; rouge2 mean: 0.18182857563776889; rougeL mean: 0.338059057605247; rougeLSum mean: 0.3459711188799051
rouge1 std: 0.010466630432432539; rouge2 std: 0.009282807987288665; rougeL std: 0.009779552772376295; rougeLSum std: 0.009572566960906694
bleu mean: 0.10230058179685986
bleu std: 0.006324689634532095
Answer paraphrased S1:
Accuracy mean: 0.7418181818181818
S2 Question generated:
BLEU MEAN Question: 0.020447273961806026 STD Question: 0.0020265099437807655
ROUGE1 MEAN Question: 0.2528370192422242 STD Question: 0.0023200078576739013
ROUGE2 MEAN Question: 0.061840429846630685 STD Question: 0.0007858525303992185
ROUGEL MEAN Question: 0.19132623066205193 STD Question: 0.0012398409057263467
ROUGELSum MEAN Question: 0.19678110802320528 STD Question: 0.003283528219370593
S2 Answer generated:
Accuracy mean: 0.71
Accuracy std: 0.008164965809277268
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.18804432, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f13602ecd30>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.7917330894063312; rouge2 mean: 0.6713486020733979; rougeL mean: 0.7285452217440078; rougeLSum mean: 0.7288934922262365
rouge1 std: 0.008421545154165076; rouge2 std: 0.009029284666808487; rougeL std: 0.007385900639540247; rougeLSum std: 0.0068167519308630865
bleu mean: 0.5795451106816142
bleu std: 0.01129853377604946
Answer paraphrased S1:
Accuracy mean: 0.660909090909091
S2 Question generated:
BLEU MEAN Question: 0.36264573841522746 STD Question: 0.005703478574909002
ROUGE1 MEAN Question: 0.6268211224532774 STD Question: 0.00737090287974566
ROUGE2 MEAN Question: 0.45978424201615414 STD Question: 0.006726317599021876
ROUGEL MEAN Question: 0.5614857815903136 STD Question: 0.0046274231465508525
ROUGELSum MEAN Question: 0.5599111049188367 STD Question: 0.004840030922073191
S2 Answer generated:
Accuracy mean: 0.6183333333333333
Accuracy std: 0.006236095644623242
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.14307304, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135edc31f0>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.9100119365739836; rouge2 mean: 0.9006261026332698; rougeL mean: 0.9098364815335767; rougeLSum mean: 0.908955728029531
rouge1 std: 0.004458054246761556; rouge2 std: 0.0050897397994564345; rougeL std: 0.004315882441102881; rougeLSum std: 0.004176543397768656
bleu mean: 0.7142483552216969
bleu std: 0.010390726093230863
Answer paraphrased S1:
Accuracy mean: 0.7595454545454546
S2 Question generated:
BLEU MEAN Question: 0.41985008561508136 STD Question: 0.0037138067052960625
ROUGE1 MEAN Question: 0.7241399634596405 STD Question: 0.006243622645302681
ROUGE2 MEAN Question: 0.7054611346247253 STD Question: 0.00621966213118055
ROUGEL MEAN Question: 0.7234749308554173 STD Question: 0.007094211422782367
ROUGELSum MEAN Question: 0.7229088381346633 STD Question: 0.00734933323906211
S2 Answer generated:
Accuracy mean: 0.7183333333333333
Accuracy std: 0.010274023338281637
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.08795220000000001, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135ec828e0>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.4847204145522626; rouge2 mean: 0.42925692086939304; rougeL mean: 0.47445001768191536; rougeLSum mean: 0.473615139954841
rouge1 std: 0.024546978119322452; rouge2 std: 0.02634171800157431; rougeL std: 0.025153417475911214; rougeLSum std: 0.025815662121141694
bleu mean: 0.3828962381514007
bleu std: 0.028501732091234893
Answer paraphrased S1:
Accuracy mean: 0.5154545454545455
S2 Question generated:
BLEU MEAN Question: 4.518761211623778e-86 STD Question: 6.3904933906038274e-86
ROUGE1 MEAN Question: 0.0010144927536231885 STD Question: 0.0014347094111031402
ROUGE2 MEAN Question: 0.000634920634920635 STD Question: 0.0008979133729352985
ROUGEL MEAN Question: 0.0010144927536231885 STD Question: 0.0014347094111031402
ROUGELSum MEAN Question: 0.0010144927536231885 STD Question: 0.0014347094111031402
S2 Answer generated:
Accuracy mean: 0.2733333333333334
Accuracy std: 0.006236095644623242
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.1393602, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f11b773fa90>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.670636020312214; rouge2 mean: 0.540290196812017; rougeL mean: 0.6407105769374054; rougeLSum mean: 0.6396154511160972
rouge1 std: 0.01289610925804306; rouge2 std: 0.013453610416274688; rougeL std: 0.011879469910071593; rougeLSum std: 0.011159885321753259
bleu mean: 0.44509573673558217
bleu std: 0.015541239519369018
Answer paraphrased S1:
Accuracy mean: 0.6377272727272728
S2 Question generated:
BLEU MEAN Question: 0.012320864105785407 STD Question: 0.0025599511104587424
ROUGE1 MEAN Question: 0.13973613278380922 STD Question: 0.005842561605443542
ROUGE2 MEAN Question: 0.07947228238797474 STD Question: 0.004456537065620183
ROUGEL MEAN Question: 0.1265475106155866 STD Question: 0.004883575302766756
ROUGELSum MEAN Question: 0.1280943228160664 STD Question: 0.005111175213386579
S2 Answer generated:
Accuracy mean: 0.3866666666666667
Accuracy std: 0.008498365855987981
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.06338552, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135c16f850>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.2275011251781902; rouge2 mean: 0.06372412872850114; rougeL mean: 0.1894875942961437; rougeLSum mean: 0.1897912572911664
rouge1 std: 0.010888583548519064; rouge2 std: 0.006891566736165576; rougeL std: 0.009077415301743979; rougeLSum std: 0.009206210028502502
bleu mean: 0.026132799021976683
bleu std: 0.004315068546741634
Answer paraphrased S1:
Accuracy mean: 0.41500000000000004
S2 Question generated:
BLEU MEAN Question: 0.009972629236739033 STD Question: 0.0016138501780416535
ROUGE1 MEAN Question: 0.10670470822801059 STD Question: 0.008811618805078166
ROUGE2 MEAN Question: 0.025507737277971204 STD Question: 0.002952761603500183
ROUGEL MEAN Question: 0.0886786588188041 STD Question: 0.00653249195066032
ROUGELSum MEAN Question: 0.08921476155379833 STD Question: 0.006760027974246922
S2 Answer generated:
Accuracy mean: 0.345
Accuracy std: 0.014719601443879732
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.07289304000000002, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 151643, 'eos_token_id': 151643, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135edc31f0>]}
Qwen/Qwen2-1.5B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.4171518849737448; rouge2 mean: 0.18511982895862564; rougeL mean: 0.3379142105911295; rougeLSum mean: 0.34754029647360896
rouge1 std: 0.007672857146208134; rouge2 std: 0.00855978747847058; rougeL std: 0.0079704040347803; rougeLSum std: 0.007321604372866668
bleu mean: 0.10303178109356112
bleu std: 0.008628292827215802
Answer paraphrased S1:
Accuracy mean: 0.6090909090909091
S2 Question generated:
BLEU MEAN Question: 0.023017259794145362 STD Question: 0.001468758885768912
ROUGE1 MEAN Question: 0.2600794849400074 STD Question: 0.004326836002940301
ROUGE2 MEAN Question: 0.06330227474528943 STD Question: 0.004499812163901572
ROUGEL MEAN Question: 0.19759591676428287 STD Question: 0.0025286367266800767
ROUGELSum MEAN Question: 0.20370700487415502 STD Question: 0.0015072858420469557
S2 Answer generated:
Accuracy mean: 0.5316666666666667
Accuracy std: 0.008498365855987981
Gap Change: nan

