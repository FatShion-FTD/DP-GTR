
25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 39, 'do_sample': True, 'temperature': 0.37608864, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd623f11130>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.8351791810635212; rouge2 mean: 0.7503978954225261; rougeL mean: 0.8153273789034835
rouge1 std: 0.006130018897400808; rouge2 std: 0.009484787592118689; rougeL std: 0.0061298513525550056
bleu mean: 0.6850414641566422
bleu std: 0.008291944457608112
Answer paraphrased S1:
rouge1 mean: 0.5131983078372563; rouge2 mean: 0.29068782382107144; rougeL mean: 0.5129030771979657
rouge1 std: 0.01006136086058727; rouge2 std: 0.007638291692771686; rougeL std: 0.009978520529418968
bleu mean: 0.17853055709624588
bleu std: 0.024099203365486294
S2 Question generated:
BLEU MEAN Question: 0.3637486467240823 STD Question: 0.009316317805460978
ROUGE1 MEAN Question: 0.5161635373390004 STD Question: 0.010872219616496313
ROUGE2 MEAN Question: 0.3782831747578379 STD Question: 0.005330712461230824
ROUGEL MEAN Question: 0.4863738523925977 STD Question: 0.00852761528306444
S2 Answer generated:
BLEU MEAN Answer: 0.06344845005238132 STD Answer: 0.004586063347095811
ROUGE1 MEAN Answer: 0.4237012222375385 STD Answer: 0.01687370073295431
ROUGE2 MEAN Answer: 0.2706755139612562 STD Answer: 0.0053277685670161685
ROUGEL MEAN Answer: 0.42190609529713313 STD Answer: 0.018514291699275036

25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 0.28614608, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd6302c99d0>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.8458989540635529; rouge2 mean: 0.8159775356271509; rougeL mean: 0.8403656950152801
rouge1 std: 0.0070574629500258996; rouge2 std: 0.009058901641739713; rougeL std: 0.007898705866299958
bleu mean: 0.584585625569603
bleu std: 0.015622381764490158
Answer paraphrased S1:
rouge1 mean: 0.5821922410509933; rouge2 mean: 0.3367177310807997; rougeL mean: 0.5808919402787246
rouge1 std: 0.007202223809535888; rouge2 std: 0.004871517969991475; rougeL std: 0.00670010747564248
bleu mean: 0.2027228432092546
bleu std: 0.004558568086009101
S2 Question generated:
BLEU MEAN Question: 0.3919261101849312 STD Question: 0.00785076300227965
ROUGE1 MEAN Question: 0.7442501700169125 STD Question: 0.007235877498173238
ROUGE2 MEAN Question: 0.70222050781025 STD Question: 0.010971493120841495
ROUGEL MEAN Question: 0.738925197665551 STD Question: 0.008669227776073176
S2 Answer generated:
BLEU MEAN Answer: 0.20275412420906813 STD Answer: 0.017816785418658488
ROUGE1 MEAN Answer: 0.5827442277413492 STD Answer: 0.007855597524790993
ROUGE2 MEAN Answer: 0.36701114000378715 STD Answer: 0.006702883288527966
ROUGEL MEAN Answer: 0.5833404978685461 STD Answer: 0.008309601368837185

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 39, 'do_sample': True, 'temperature': 0.37608864, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f96578b7d90>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.82975990363785; rouge2 mean: 0.747957843359704; rougeL mean: 0.812314069413334
rouge1 std: 0.009710593247531991; rouge2 std: 0.00929532527752331; rougeL std: 0.007426615172626859
bleu mean: 0.6839122585438996
bleu std: 0.012580738693402444
Answer paraphrased S1:
rouge1 mean: 0.516413644101468; rouge2 mean: 0.2912482151647841; rougeL mean: 0.5163146195138002
rouge1 std: 0.013055276386491165; rouge2 std: 0.011783098435240552; rougeL std: 0.012984902427348278
bleu mean: 0.1845037808861361
bleu std: 0.0190342485929678
S2 Question generated:
BLEU MEAN Question: 0.3987223748017366 STD Question: 0.0074729432482039905
ROUGE1 MEAN Question: 0.5682785861898845 STD Question: 0.024308881235850354
ROUGE2 MEAN Question: 0.42895182937547127 STD Question: 0.018219642012423393
ROUGEL MEAN Question: 0.5408474732836451 STD Question: 0.02176028822356214
S2 Answer generated:
BLEU MEAN Answer: 0.08947319706095237 STD Answer: 0.009067038929028489
ROUGE1 MEAN Answer: 0.4640814654759306 STD Answer: 0.01175874041300925
ROUGE2 MEAN Answer: 0.3038660608071873 STD Answer: 0.01448707731968606
ROUGEL MEAN Answer: 0.4645954552349041 STD Answer: 0.013229575840788507

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 0.28614608, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f96578b7ee0>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.8470119639183772; rouge2 mean: 0.8175073230246515; rougeL mean: 0.8414353213031484
rouge1 std: 0.0037431574585963774; rouge2 std: 0.00280772285535284; rougeL std: 0.002783760761579034
bleu mean: 0.5887779855942281
bleu std: 0.008316956195525535
Answer paraphrased S1:
rouge1 mean: 0.579323105015303; rouge2 mean: 0.33739760922274775; rougeL mean: 0.5796428725481552
rouge1 std: 0.006509845982251695; rouge2 std: 0.004704357522868332; rougeL std: 0.005845892504362662
bleu mean: 0.20139299949207598
bleu std: 0.004951116466722208
S2 Question generated:
BLEU MEAN Question: 0.3181722575472597 STD Question: 0.009948288929752533
ROUGE1 MEAN Question: 0.6729927017861584 STD Question: 0.015129776000040167
ROUGE2 MEAN Question: 0.6282840131482404 STD Question: 0.018353489029205534
ROUGEL MEAN Question: 0.6663228715491069 STD Question: 0.01568085792742669
S2 Answer generated:
BLEU MEAN Answer: 0.1675324745418676 STD Answer: 0.02488220260897204
ROUGE1 MEAN Answer: 0.5422752907552314 STD Answer: 0.013720140489854704
ROUGE2 MEAN Answer: 0.34137059672353787 STD Answer: 0.014630229066521004
ROUGEL MEAN Answer: 0.5399694447126933 STD Answer: 0.014186117514352161

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 0.17590440000000002, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc067a0d070>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.49337645700560756; rouge2 mean: 0.4214971967086072; rougeL mean: 0.47830257382466834
rouge1 std: 0.025872018728305208; rouge2 std: 0.025373169671648866; rougeL std: 0.026550820189358657
bleu mean: 0.35560602668329155
bleu std: 0.03118287158752092
Answer paraphrased S1:
rouge1 mean: 0.2830530800526571; rouge2 mean: 0.15336408263380397; rougeL mean: 0.28145959625139133
rouge1 std: 0.022541267809174627; rouge2 std: 0.016426650011056098; rougeL std: 0.02235622763823926
bleu mean: 0.06989528700620953
bleu std: 0.012150273265072701
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.01758155741359077 STD Question: 0.0037051289780481583
ROUGE2 MEAN Question: 0.007332603948902761 STD Question: 0.001042659215531893
ROUGEL MEAN Question: 0.016987120426787298 STD Question: 0.003504247247571069
S2 Answer generated:
BLEU MEAN Answer: 0.005699807380600379 STD Answer: 0.0010628779317941788
ROUGE1 MEAN Answer: 0.04301324497136325 STD Answer: 0.002062365878522245
ROUGE2 MEAN Answer: 0.016131169783642763 STD Answer: 0.0014689843258050778
ROUGEL MEAN Answer: 0.04105189204034224 STD Answer: 0.0011426932634684217

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 0.2787204, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc049381340>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.6000214286187341; rouge2 mean: 0.5089440683219034; rougeL mean: 0.5812953862935246
rouge1 std: 0.020063725973675485; rouge2 std: 0.017654487893292947; rougeL std: 0.018969667875242655
bleu mean: 0.4341598820566746
bleu std: 0.021711016694504166
Answer paraphrased S1:
rouge1 mean: 0.37417299276121035; rouge2 mean: 0.2073692597509414; rougeL mean: 0.3735941837227763
rouge1 std: 0.018840377168173657; rouge2 std: 0.01598150627481172; rougeL std: 0.018545533091237753
bleu mean: 0.13049117042517497
bleu std: 0.014627842644869354
S2 Question generated:
BLEU MEAN Question: 3.5329866097535846e-21 STD Question: 4.9963975791960605e-21
ROUGE1 MEAN Question: 0.005457854406130269 STD Question: 0.0049031226334698
ROUGE2 MEAN Question: 0.004074074074074074 STD Question: 0.0033264675519277726
ROUGEL MEAN Question: 0.005316091954022988 STD Question: 0.004717722242525157
S2 Answer generated:
BLEU MEAN Answer: 0.00600548001514271 STD Answer: 0.0012390595982465277
ROUGE1 MEAN Answer: 0.04147173604259518 STD Answer: 0.004667664452057096
ROUGE2 MEAN Answer: 0.018251773340328327 STD Answer: 0.003908823455261645
ROUGEL MEAN Answer: 0.03953676371071882 STD Answer: 0.004168884257548799

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 69, 'do_sample': True, 'temperature': 0.12677104, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc067a1c6a0>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.308055538966122; rouge2 mean: 0.16287581645095706; rougeL mean: 0.2886604087792345
rouge1 std: 0.010680445624805572; rouge2 std: 0.010701058243812888; rougeL std: 0.009840076263834393
bleu mean: 0.08044204688605254
bleu std: 0.007398878973293188
Answer paraphrased S1:
rouge1 mean: 0.17421589741937027; rouge2 mean: 0.09913164400719977; rougeL mean: 0.1730278454043776
rouge1 std: 0.02030803900386567; rouge2 std: 0.012387079462372004; rougeL std: 0.020230757040875482
bleu mean: 0.03642788852289251
bleu std: 0.011469309923873353
S2 Question generated:
BLEU MEAN Question: 0.02119513104384609 STD Question: 0.009269186845400216
ROUGE1 MEAN Question: 0.09927730759941789 STD Question: 0.012584587338411187
ROUGE2 MEAN Question: 0.035929709218166336 STD Question: 0.010686625897465999
ROUGEL MEAN Question: 0.09155246936264028 STD Question: 0.011664942700415865
S2 Answer generated:
BLEU MEAN Answer: 0.016827145552815864 STD Answer: 0.0042563188941698174
ROUGE1 MEAN Answer: 0.09115005305087648 STD Answer: 0.007490199964740503
ROUGE2 MEAN Answer: 0.052937891801152076 STD Answer: 0.0016304735011638933
ROUGEL MEAN Answer: 0.08934603370345647 STD Answer: 0.006994790323969758
