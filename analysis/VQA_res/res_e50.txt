
25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 39, 'do_sample': True, 'temperature': 0.75217728, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd630e32700>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.7137036222511427; rouge2 mean: 0.5905003647139967; rougeL mean: 0.6889729224372325
rouge1 std: 0.010726365650085213; rouge2 std: 0.012227833774863953; rougeL std: 0.00954632947358209
bleu mean: 0.48437005858262433
bleu std: 0.014614914725814686
Answer paraphrased S1:
rouge1 mean: 0.454686960511282; rouge2 mean: 0.25580509347701064; rougeL mean: 0.4540855869828006
rouge1 std: 0.018553066973343715; rouge2 std: 0.010674296182390536; rougeL std: 0.018616483138418696
bleu mean: 0.15189080923706644
bleu std: 0.014792463109139268
S2 Question generated:
BLEU MEAN Question: 0.21563541311048617 STD Question: 0.00957234681310104
ROUGE1 MEAN Question: 0.3867410256151069 STD Question: 0.016757949877151703
ROUGE2 MEAN Question: 0.2406278712332365 STD Question: 0.01655309964721168
ROUGEL MEAN Question: 0.3568260581242746 STD Question: 0.015888749644246334
S2 Answer generated:
BLEU MEAN Answer: 0.045417493696199907 STD Answer: 0.008513348841587772
ROUGE1 MEAN Answer: 0.29760584848885635 STD Answer: 0.005091726780187854
ROUGE2 MEAN Answer: 0.1689495438681042 STD Answer: 0.016773685473764156
ROUGEL MEAN Answer: 0.2958971431817446 STD Answer: 0.006396620195630489

25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 0.57229216, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd623fbe880>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.7956530663666577; rouge2 mean: 0.754480336999224; rougeL mean: 0.7855460074580871
rouge1 std: 0.01126300483514331; rouge2 std: 0.013955191711099307; rougeL std: 0.012250533283807905
bleu mean: 0.48143288683184965
bleu std: 0.016106344928609316
Answer paraphrased S1:
rouge1 mean: 0.5450272597395863; rouge2 mean: 0.31541474884588827; rougeL mean: 0.5437914153245086
rouge1 std: 0.008631325225456945; rouge2 std: 0.007827478971564545; rougeL std: 0.007917919996108469
bleu mean: 0.19028241089577003
bleu std: 0.012054167515748566
S2 Question generated:
BLEU MEAN Question: 0.22588264324999419 STD Question: 0.000581952863878163
ROUGE1 MEAN Question: 0.6224703375117505 STD Question: 0.01032773940477781
ROUGE2 MEAN Question: 0.5578166262100327 STD Question: 0.010067064054842437
ROUGEL MEAN Question: 0.6045505783944268 STD Question: 0.009656732016414335
S2 Answer generated:
BLEU MEAN Answer: 0.1270016392691427 STD Answer: 0.009786390850266198
ROUGE1 MEAN Answer: 0.5042863328236361 STD Answer: 0.016300274621887236
ROUGE2 MEAN Answer: 0.3314383732255116 STD Answer: 0.011939222788460841
ROUGEL MEAN Answer: 0.5019148405339963 STD Answer: 0.015695252344034176

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 47, 'do_sample': True, 'temperature': 0.75217728, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f95859afbe0>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.7004400016162503; rouge2 mean: 0.5735583049199072; rougeL mean: 0.6749215218105672
rouge1 std: 0.01237152808712554; rouge2 std: 0.017360348416053092; rougeL std: 0.012733806691527561
bleu mean: 0.47481238837719086
bleu std: 0.02348402778330043
Answer paraphrased S1:
rouge1 mean: 0.4380973951766723; rouge2 mean: 0.24276978138053196; rougeL mean: 0.43851210790857814
rouge1 std: 0.024050599499047604; rouge2 std: 0.023370163282120923; rougeL std: 0.024328712671437575
bleu mean: 0.12806811134436524
bleu std: 0.020327850147252836
S2 Question generated:
BLEU MEAN Question: 0.2044181156992971 STD Question: 0.007219928256083236
ROUGE1 MEAN Question: 0.3906366794833644 STD Question: 0.004516116844952896
ROUGE2 MEAN Question: 0.24493231361902498 STD Question: 0.004561103840169585
ROUGEL MEAN Question: 0.36144761477389187 STD Question: 0.0061549799530473915
S2 Answer generated:
BLEU MEAN Answer: 0.056132474966902456 STD Answer: 0.006427067891874238
ROUGE1 MEAN Answer: 0.333436167448019 STD Answer: 0.01770007597355699
ROUGE2 MEAN Answer: 0.21586236590982325 STD Answer: 0.017188069731335326
ROUGEL MEAN Answer: 0.3341429956884124 STD Answer: 0.017108476884476635

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 0.57229216, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f965786deb0>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.7869037074912442; rouge2 mean: 0.7472177333688422; rougeL mean: 0.7782263980390632
rouge1 std: 0.013323138280860602; rouge2 std: 0.014874111125405542; rougeL std: 0.013844649547797636
bleu mean: 0.46901061181743864
bleu std: 0.025548940093059472
Answer paraphrased S1:
rouge1 mean: 0.5292012954615569; rouge2 mean: 0.3090685581730705; rougeL mean: 0.5290257718793732
rouge1 std: 0.012316210857363794; rouge2 std: 0.008512225248718175; rougeL std: 0.012375577956267772
bleu mean: 0.18794205780546125
bleu std: 0.006346212056196768
S2 Question generated:
BLEU MEAN Question: 0.21397334171716564 STD Question: 0.01031422465178004
ROUGE1 MEAN Question: 0.5779067353897317 STD Question: 0.013147791781345536
ROUGE2 MEAN Question: 0.5229018733071129 STD Question: 0.012437732804865074
ROUGEL MEAN Question: 0.5642333536119563 STD Question: 0.01374676956916224
S2 Answer generated:
BLEU MEAN Answer: 0.16186575381265136 STD Answer: 0.01787610329588367
ROUGE1 MEAN Answer: 0.461237409043042 STD Answer: 0.013902883944417486
ROUGE2 MEAN Answer: 0.30362519363120866 STD Answer: 0.012075798999804859
ROUGEL MEAN Answer: 0.46057354524033817 STD Answer: 0.014318146294567891

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 0.35180880000000003, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc0447c7790>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.44691467030835647; rouge2 mean: 0.35431426993925474; rougeL mean: 0.42819980081905046
rouge1 std: 0.012296040032808457; rouge2 std: 0.014604056033807588; rougeL std: 0.012374662786863867
bleu mean: 0.31239844033571335
bleu std: 0.013864111432694491
Answer paraphrased S1:
rouge1 mean: 0.26357260125535914; rouge2 mean: 0.14533089147016123; rougeL mean: 0.26168286985223077
rouge1 std: 0.025787388020740633; rouge2 std: 0.017917368967286924; rougeL std: 0.026543845389031304
bleu mean: 0.07265970832832212
bleu std: 0.012689491258852135
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.02959913101766144 STD Question: 0.0037728164277700278
ROUGE2 MEAN Question: 0.011471315714156272 STD Question: 0.0009761571365159951
ROUGEL MEAN Question: 0.029077954377251053 STD Question: 0.003310089066965845
S2 Answer generated:
BLEU MEAN Answer: 0.0036421660801757108 STD Answer: 0.0009033326478787559
ROUGE1 MEAN Answer: 0.03206886981816677 STD Answer: 0.00297389152151322
ROUGE2 MEAN Answer: 0.010393951005101073 STD Answer: 0.003165225547919729
ROUGEL MEAN Answer: 0.030363167834917066 STD Answer: 0.0037118433845476557

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 0.5574408, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc067ab4130>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.4802650762939615; rouge2 mean: 0.3523078985083736; rougeL mean: 0.45432075696387303
rouge1 std: 0.01906737197971382; rouge2 std: 0.016345570329283785; rougeL std: 0.01940493275802097
bleu mean: 0.2887185463349635
bleu std: 0.01237443529198615
Answer paraphrased S1:
rouge1 mean: 0.30118844054553223; rouge2 mean: 0.16398941343374965; rougeL mean: 0.30018328191280824
rouge1 std: 0.019934004873227135; rouge2 std: 0.014999077975159673; rougeL std: 0.019887207343421472
bleu mean: 0.0905770996194153
bleu std: 0.017122297115230344
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.004517753700012416 STD Question: 0.0016600228064588105
ROUGE2 MEAN Question: 0.0008522727272727272 STD Question: 0.0007748966873287418
ROUGEL MEAN Question: 0.004288885785049468 STD Question: 0.0015217086647475852
S2 Answer generated:
BLEU MEAN Answer: 0.0050638237332267105 STD Answer: 0.00044854656026536256
ROUGE1 MEAN Answer: 0.036514882938345754 STD Answer: 0.0017916615883123408
ROUGE2 MEAN Answer: 0.014023932901599609 STD Answer: 0.0006940703057403356
ROUGEL MEAN Answer: 0.035023740183038915 STD Answer: 0.0016288808485792562

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 68, 'do_sample': True, 'temperature': 0.25354208, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc0493817c0>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.3054682551957502; rouge2 mean: 0.14391955619425925; rougeL mean: 0.2820221276442316
rouge1 std: 0.015559063204994884; rouge2 std: 0.012954431608635547; rougeL std: 0.015203238985498288
bleu mean: 0.06028742127086515
bleu std: 0.0063449328155632725
Answer paraphrased S1:
rouge1 mean: 0.1745509923895671; rouge2 mean: 0.10003918720294985; rougeL mean: 0.17364899295299718
rouge1 std: 0.020877969390842337; rouge2 std: 0.014779785553380297; rougeL std: 0.020784099894560985
bleu mean: 0.03615725865001637
bleu std: 0.008603351563321622
S2 Question generated:
BLEU MEAN Question: 0.017621381392228432 STD Question: 0.0026051332485613017
ROUGE1 MEAN Question: 0.10636399682721703 STD Question: 0.005230772331669254
ROUGE2 MEAN Question: 0.03373130628414508 STD Question: 0.003690229789809897
ROUGEL MEAN Question: 0.09802501014749058 STD Question: 0.005944583951552662
S2 Answer generated:
BLEU MEAN Answer: 0.012216107274502529 STD Answer: 0.0019316583330259314
ROUGE1 MEAN Answer: 0.06296796454271945 STD Answer: 0.009949829700301817
ROUGE2 MEAN Answer: 0.03563038528414916 STD Answer: 0.009462563076774035
ROUGEL MEAN Answer: 0.062202169400182826 STD Answer: 0.010904175957919373
