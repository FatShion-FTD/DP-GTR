
25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 36, 'do_sample': True, 'temperature': 3.7608863999999995, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c8362e80>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.10121025667042911; rouge2 mean: 0.005652899818512114; rougeL mean: 0.08145366999292741; rougeLSum mean: 0.08139618013412385
rouge1 std: 0.004275423281775319; rouge2 std: 0.0019019488958089172; rougeL std: 0.0035689941889764025; rougeLSum std: 0.003586332239792534
bleu mean: 0.00019652591623087225
bleu std: 0.0006214695145410097
Answer paraphrased S1:
Accuracy mean: 0.5018181818181818
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.05957612407600519 STD Question: 0.005179743030679576
ROUGE2 MEAN Question: 0.0011253392371018414 STD Question: 0.000392051509540295
ROUGEL MEAN Question: 0.04926432066706171 STD Question: 0.004284862752791126
ROUGELSum MEAN Question: 0.04920308618898391 STD Question: 0.004377962472777463
S2 Answer generated:
Accuracy mean: 0.44
Accuracy std: 0.007071067811865482
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 65, 'do_sample': True, 'temperature': 2.8614608000000006, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c831fee0>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.12703538805549394; rouge2 mean: 0.015505310738595325; rougeL mean: 0.1031792854439205; rougeLSum mean: 0.10507406473636438
rouge1 std: 0.006354841725463283; rouge2 std: 0.002574173815766324; rougeL std: 0.006717571998244998; rougeLSum std: 0.0063669549855393
bleu mean: 0.00913267185967019
bleu std: 0.0007920766821551688
Answer paraphrased S1:
Accuracy mean: 0.48272727272727267
S2 Question generated:
BLEU MEAN Question: 0.0028862265112787077 STD Question: 3.494265810775574e-05
ROUGE1 MEAN Question: 0.05986215171483874 STD Question: 0.002337328777419337
ROUGE2 MEAN Question: 0.003697018195972051 STD Question: 0.0002900447116744918
ROUGEL MEAN Question: 0.043219535503460894 STD Question: 0.002257042675499824
ROUGELSum MEAN Question: 0.04735805704737345 STD Question: 0.0027414526714799503
S2 Answer generated:
Accuracy mean: 0.365
Accuracy std: 0.014719601443879758
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 64, 'do_sample': True, 'temperature': 1.759044, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9b41170a0>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.11812568962019071; rouge2 mean: 0.009640615210591962; rougeL mean: 0.09561235887426155; rougeLSum mean: 0.09553490206820747
rouge1 std: 0.00651756556974669; rouge2 std: 0.0022241410002515572; rougeL std: 0.005095684520362365; rougeLSum std: 0.005013551856256935
bleu mean: 0.000352164802312211
bleu std: 0.0011136428870495184
Answer paraphrased S1:
Accuracy mean: 0.5604545454545455
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.05328530024210354 STD Question: 0.0050453748931609975
ROUGE2 MEAN Question: 0.0017776061602898187 STD Question: 0.0003432128323130291
ROUGEL MEAN Question: 0.04549660926392161 STD Question: 0.0034335909043464135
ROUGELSum MEAN Question: 0.045348295435669796 STD Question: 0.0035458679088581136
S2 Answer generated:
Accuracy mean: 0.5083333333333333
Accuracy std: 0.010274023338281637
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 41, 'do_sample': True, 'temperature': 2.787204, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c831f880>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.13196823293716897; rouge2 mean: 0.010047094429247557; rougeL mean: 0.1050280566264656; rougeLSum mean: 0.10486137109872126
rouge1 std: 0.004617839291868512; rouge2 std: 0.0022684873268610487; rougeL std: 0.005392901941567025; rougeLSum std: 0.005321709102256877
bleu mean: 0.000837516223467688
bleu std: 0.0019191629907101466
Answer paraphrased S1:
Accuracy mean: 0.5777272727272728
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.07381935285149546 STD Question: 0.00794781407898465
ROUGE2 MEAN Question: 0.0024636120283411038 STD Question: 0.00039463292993843454
ROUGEL MEAN Question: 0.060019520780465824 STD Question: 0.006325403712232809
ROUGELSum MEAN Question: 0.059961090053262105 STD Question: 0.006490159924536335
S2 Answer generated:
Accuracy mean: 0.5033333333333334
Accuracy std: 0.034237730973623565
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 53, 'do_sample': True, 'temperature': 1.2677104, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c0149df0>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.11978536941544445; rouge2 mean: 0.00844526386460173; rougeL mean: 0.09772348781190839; rougeLSum mean: 0.09761047651396502
rouge1 std: 0.007378084269041723; rouge2 std: 0.002359010878702357; rougeL std: 0.0051823894547162845; rougeLSum std: 0.0051371114994060866
bleu mean: 0.0007861105277598298
bleu std: 0.0016721388003555497
Answer paraphrased S1:
Accuracy mean: 0.5427272727272728
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.061484904758273534 STD Question: 0.0032606695952553835
ROUGE2 MEAN Question: 0.001105277105989784 STD Question: 0.00034492782531248873
ROUGEL MEAN Question: 0.05061875482034783 STD Question: 0.0022512561081351598
ROUGELSum MEAN Question: 0.05036747041607468 STD Question: 0.0022646178710219104
S2 Answer generated:
Accuracy mean: 0.5116666666666667
Accuracy std: 0.024944382578492966
Gap Change: nan

25% Avoid lowest ppl reference ICL 2-choice Experiment:
Config: {'max_new_tokens': 63, 'do_sample': True, 'temperature': 1.4578608000000002, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 151643, 'eos_token_id': 151643, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd9c81c24c0>]}
Qwen/Qwen2-1.5B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.010158483178144254; rouge2 mean: 0.0008038360316445953; rougeL mean: 0.008906045676067635; rougeLSum mean: 0.008920402599506386
rouge1 std: 0.002242119315521761; rouge2 std: 0.0005733255076019794; rougeL std: 0.0017028021491557676; rougeLSum std: 0.0016851173303378637
bleu mean: 0.0
bleu std: 0.0
Answer paraphrased S1:
Accuracy mean: 0.2877272727272728
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.013717608739748555 STD Question: 0.0011330968264148045
ROUGE2 MEAN Question: 0.0005281059970266617 STD Question: 7.638155080689781e-05
ROUGEL MEAN Question: 0.012628709288235444 STD Question: 0.0012149094530432222
ROUGELSum MEAN Question: 0.012849695057466255 STD Question: 0.0009522847945608372
S2 Answer generated:
Accuracy mean: 0.2783333333333333
Accuracy std: 0.01433720877840437
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 38, 'do_sample': True, 'temperature': 3.7608863999999995, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135eded7c0>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.0988208765938531; rouge2 mean: 0.006178325674961629; rougeL mean: 0.07905979102227317; rougeLSum mean: 0.07886684565405765
rouge1 std: 0.00549094742446179; rouge2 std: 0.0013631842882920319; rougeL std: 0.004080141928234775; rougeLSum std: 0.004059084878006779
bleu mean: 0.0005392437836734047
bleu std: 0.0011785147706349273
Answer paraphrased S1:
Accuracy mean: 0.32681818181818173
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.05739664318825616 STD Question: 0.0049920055237390095
ROUGE2 MEAN Question: 0.0009255415444187894 STD Question: 0.0002849978132844029
ROUGEL MEAN Question: 0.04620343060092635 STD Question: 0.0036223827251473406
ROUGELSum MEAN Question: 0.046107226389084134 STD Question: 0.0036881368072405095
S2 Answer generated:
Accuracy mean: 0.3016666666666667
Accuracy std: 0.02867441755680876
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 65, 'do_sample': True, 'temperature': 2.8614608000000006, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135c178b50>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.12770902567790812; rouge2 mean: 0.01591587703418977; rougeL mean: 0.10335294110792798; rougeLSum mean: 0.1054308506220595
rouge1 std: 0.008552179945994769; rouge2 std: 0.0025523195832734616; rougeL std: 0.007487405004593181; rougeLSum std: 0.007954209318641721
bleu mean: 0.00940175826816232
bleu std: 0.0006800129504589642
Answer paraphrased S1:
Accuracy mean: 0.34045454545454545
S2 Question generated:
BLEU MEAN Question: 0.002751362113767199 STD Question: 3.7507300833010465e-05
ROUGE1 MEAN Question: 0.05885234620924426 STD Question: 0.002859019578048184
ROUGE2 MEAN Question: 0.002924217393996464 STD Question: 0.0007213515806838923
ROUGEL MEAN Question: 0.041668699931882526 STD Question: 0.0023212736646356967
ROUGELSum MEAN Question: 0.04619537561939705 STD Question: 0.0025805547429418535
S2 Answer generated:
Accuracy mean: 0.3116666666666667
Accuracy std: 0.015456030825826186
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 41, 'do_sample': True, 'temperature': 1.759044, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135ee18b50>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.11528095846753086; rouge2 mean: 0.008768292677255176; rougeL mean: 0.09310960850387354; rougeLSum mean: 0.09320188211540627
rouge1 std: 0.0054605547282143415; rouge2 std: 0.0013709071447939633; rougeL std: 0.004041101273668295; rougeLSum std: 0.004119945421809657
bleu mean: 0.0
bleu std: 0.0
Answer paraphrased S1:
Accuracy mean: 0.32999999999999996
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.05869259714705546 STD Question: 0.00578901718853102
ROUGE2 MEAN Question: 0.0013376033500304132 STD Question: 0.0005405857538608876
ROUGEL MEAN Question: 0.04986278425305366 STD Question: 0.004777758389644273
ROUGELSum MEAN Question: 0.04996182572907376 STD Question: 0.004809677641201998
S2 Answer generated:
Accuracy mean: 0.28833333333333333
Accuracy std: 0.008498365855987964
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 21, 'do_sample': True, 'temperature': 2.787204, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135c135d60>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.12637179697178838; rouge2 mean: 0.008729422467618151; rougeL mean: 0.09953791097691096; rougeLSum mean: 0.09958331225137497
rouge1 std: 0.006687920024457139; rouge2 std: 0.002086466611368244; rougeL std: 0.0052199157754539245; rougeLSum std: 0.005345043425170134
bleu mean: 0.000541386765955501
bleu std: 0.0011487154027948734
Answer paraphrased S1:
Accuracy mean: 0.3731818181818181
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.07322812584487097 STD Question: 0.0016649743049849
ROUGE2 MEAN Question: 0.002249131534800508 STD Question: 0.00028844689421263215
ROUGEL MEAN Question: 0.059346939621190475 STD Question: 0.002822084510228416
ROUGELSum MEAN Question: 0.05932890930074226 STD Question: 0.002955912927623824
S2 Answer generated:
Accuracy mean: 0.31666666666666665
Accuracy std: 0.0023570226039551605
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 66, 'do_sample': True, 'temperature': 1.2677104, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f1366c0de50>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.1218296254926305; rouge2 mean: 0.008664893051332863; rougeL mean: 0.0996934405241468; rougeLSum mean: 0.09989781577671165
rouge1 std: 0.007314813190538738; rouge2 std: 0.0018349797751845733; rougeL std: 0.005224751089827568; rougeLSum std: 0.005261446661580059
bleu mean: 0.0008732619410558092
bleu std: 0.0014293180625012413
Answer paraphrased S1:
Accuracy mean: 0.33499999999999996
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.05830138071367996 STD Question: 0.0019179506717798926
ROUGE2 MEAN Question: 0.0013393078976203876 STD Question: 0.00036146644594224067
ROUGEL MEAN Question: 0.04932569980570503 STD Question: 0.0034819271523301542
ROUGELSum MEAN Question: 0.049493117851988365 STD Question: 0.0035789131146499818
S2 Answer generated:
Accuracy mean: 0.27
Accuracy std: 0.014719601443879739
Gap Change: nan

25% Avoid lowest ppl reference ICL 4-choice Experiment:
Config: {'max_new_tokens': 47, 'do_sample': True, 'temperature': 1.4578608000000002, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 151643, 'eos_token_id': 151643, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f135ee36bb0>]}
Qwen/Qwen2-1.5B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.009111298197172704; rouge2 mean: 0.0006636715880605318; rougeL mean: 0.007759398182911107; rougeLSum mean: 0.007885976729220001
rouge1 std: 0.0021852732888515865; rouge2 std: 0.0004367547180409337; rougeL std: 0.0016991084355745657; rougeLSum std: 0.001742089492937726
bleu mean: 8.38806564875757e-05
bleu std: 0.00026525392613091855
Answer paraphrased S1:
Accuracy mean: 0.22045454545454543
S2 Question generated:
BLEU MEAN Question: 0.0 STD Question: 0.0
ROUGE1 MEAN Question: 0.013980218608316384 STD Question: 0.0010679827676871058
ROUGE2 MEAN Question: 0.00027745193874226134 STD Question: 6.765888887891112e-05
ROUGEL MEAN Question: 0.012346184015445747 STD Question: 0.0005890204103754631
ROUGELSum MEAN Question: 0.012514198638464048 STD Question: 0.0006534043521850955
S2 Answer generated:
Accuracy mean: 0.20333333333333334
Accuracy std: 0.023213980461973528
Gap Change: nan
