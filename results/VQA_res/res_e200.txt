
25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.18804432, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd630b1bd60>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.8613462681970503; rouge2 mean: 0.7886500964537236; rougeL mean: 0.8441955631299347
rouge1 std: 0.008447393112971635; rouge2 std: 0.010437806068410691; rougeL std: 0.008829488178287074
bleu mean: 0.7346614102026346
bleu std: 0.012707300920019244
Answer paraphrased S1:
rouge1 mean: 0.5308053875753361; rouge2 mean: 0.2984864955575194; rougeL mean: 0.5298164483353949
rouge1 std: 0.00881801584550608; rouge2 std: 0.007623599601603195; rougeL std: 0.008347529625856026
bleu mean: 0.19121473888195106
bleu std: 0.019925386655068187
S2 Question generated:
BLEU MEAN Question: 0.47482619776278995 STD Question: 0.015525315997293287
ROUGE1 MEAN Question: 0.6224895396976406 STD Question: 0.011435454283611136
ROUGE2 MEAN Question: 0.504011386165402 STD Question: 0.013618525603520138
ROUGEL MEAN Question: 0.6006251180043823 STD Question: 0.01122384916162443
S2 Answer generated:
BLEU MEAN Answer: 0.11165978246311746 STD Answer: 0.006007476132198206
ROUGE1 MEAN Answer: 0.5204965470435441 STD Answer: 0.0035046845024784942
ROUGE2 MEAN Answer: 0.3254957704810646 STD Answer: 0.011390146379734284
ROUGEL MEAN Answer: 0.5185692966124559 STD Answer: 0.004310666686225906

25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.14307304, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd6302b13d0>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.8606257375252885; rouge2 mean: 0.8327590967013357; rougeL mean: 0.855138164736243
rouge1 std: 0.002477191043778529; rouge2 std: 0.0033880609092628244; rougeL std: 0.0025358087267984383
bleu mean: 0.6203536865761458
bleu std: 0.0036126537394822046
Answer paraphrased S1:
rouge1 mean: 0.5857960932739471; rouge2 mean: 0.3400720571982496; rougeL mean: 0.5842876581712032
rouge1 std: 0.005948828099775756; rouge2 std: 0.003368061386078296; rougeL std: 0.005922331881530203
bleu mean: 0.20044110734251863
bleu std: 0.0029516895802269784
S2 Question generated:
BLEU MEAN Question: 0.45336255187944635 STD Question: 0.004301468048141824
ROUGE1 MEAN Question: 0.7808621217536823 STD Question: 0.005630738746855036
ROUGE2 MEAN Question: 0.7429555963025116 STD Question: 0.006413518928645334
ROUGEL MEAN Question: 0.7739127397397901 STD Question: 0.0057821476841410846
S2 Answer generated:
BLEU MEAN Answer: 0.2269080849222542 STD Answer: 0.018460294730032547
ROUGE1 MEAN Answer: 0.613491453010968 STD Answer: 0.01662974302653638
ROUGE2 MEAN Answer: 0.3844497071555895 STD Answer: 0.011414703179656534
ROUGEL MEAN Answer: 0.6102363111847476 STD Answer: 0.014692702914408952

25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.08795220000000001, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd623fbed90>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.5016746544236796; rouge2 mean: 0.43916767254284267; rougeL mean: 0.48878260824121045
rouge1 std: 0.020906408896714638; rouge2 std: 0.020466023719921445; rougeL std: 0.0200945998270982
bleu mean: 0.3725152435241673
bleu std: 0.019651244779045174
Answer paraphrased S1:
rouge1 mean: 0.2902758229707057; rouge2 mean: 0.1618019921358774; rougeL mean: 0.2880222008721314
rouge1 std: 0.014600446762443528; rouge2 std: 0.01293806179082682; rougeL std: 0.014551575803823607
bleu mean: 0.07788499581816756
bleu std: 0.011673331057079718

25% Tokens Avoid lowest ppl reference ICL all_clip Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.18804432, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f42f01b4f70>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.9370962247084079; rouge2 mean: 0.8722864158239652; rougeL mean: 0.917928140525676
rouge1 std: 0.01031064925566239; rouge2 std: 0.014335152632233054; rougeL std: 0.010581296925480285
bleu mean: 0.8565288261504869
bleu std: 0.0258626674434305
Answer paraphrased S1:
rouge1 mean: 0.4738488783943329; rouge2 mean: 0.2122372598162072; rougeL mean: 0.4781778827233372
rouge1 std: 0.02043651418614853; rouge2 std: 0.021204354815972673; rougeL std: 0.018315743846076524
bleu mean: 0.13359287559458535
bleu std: 0.0437233962750129
S2 Question generated:
BLEU MEAN Question: 0.6325538020793126 STD Question: 0.0741928422471196
ROUGE1 MEAN Question: 0.8158729549790932 STD Question: 0.03939820621988085
ROUGE2 MEAN Question: 0.6743369673804457 STD Question: 0.03904832178671357
ROUGEL MEAN Question: 0.7920197702269314 STD Question: 0.03513752127690907
S2 Answer generated:
BLEU MEAN Answer: 0.2240224060702696 STD Answer: 0.025698366089379757
ROUGE1 MEAN Answer: 0.6950757575757575 STD Answer: 0.11645124740044775
ROUGE2 MEAN Answer: 0.37407407407407406 STD Answer: 0.05315814849780492
ROUGEL MEAN Answer: 0.6950757575757575 STD Answer: 0.11645124740044775

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.18804432, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f96577fdd30>]}
TinyLlama/TinyLlama-1.1B-Chat-v1.0 S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.8632406676094103; rouge2 mean: 0.7934769861319722; rougeL mean: 0.8471069416338941
rouge1 std: 0.010315934030566387; rouge2 std: 0.012981178974915894; rougeL std: 0.010570479894297763
bleu mean: 0.7411267731256621
bleu std: 0.014893246843036107
Answer paraphrased S1:
rouge1 mean: 0.5309055580948729; rouge2 mean: 0.29738499466051244; rougeL mean: 0.5307149407252886
rouge1 std: 0.011535298503530515; rouge2 std: 0.008576022449512208; rougeL std: 0.011015209080074967
bleu mean: 0.19963234484524275
bleu std: 0.014799021576474091
S2 Question generated:
BLEU MEAN Question: 0.5279532197045466 STD Question: 0.004605172108317798
ROUGE1 MEAN Question: 0.7058628609707008 STD Question: 0.0023930426707453032
ROUGE2 MEAN Question: 0.5859927296639392 STD Question: 0.00303137751248395
ROUGEL MEAN Question: 0.6825959852320386 STD Question: 0.0014166995417836468
S2 Answer generated:
BLEU MEAN Answer: 0.13901181860252806 STD Answer: 0.009764051483999713
ROUGE1 MEAN Answer: 0.5846747270146854 STD Answer: 0.012649143418184298
ROUGE2 MEAN Answer: 0.370965928949514 STD Answer: 0.010710823972087636
ROUGEL MEAN Answer: 0.583680389932765 STD Answer: 0.012538316219642628

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.14307304, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 128001, 'eos_token_id': 128001, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f965e614f10>]}
meta-llama/Llama-3.2-1B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.8586038128395255; rouge2 mean: 0.8316322462998268; rougeL mean: 0.8544304443928041
rouge1 std: 0.0026455772899537772; rouge2 std: 0.0034799579894224833; rougeL std: 0.0033711329607780125
bleu mean: 0.6186222700573202
bleu std: 0.005074704160754701
Answer paraphrased S1:
rouge1 mean: 0.5838842461608168; rouge2 mean: 0.3408120025173353; rougeL mean: 0.5845808238933703
rouge1 std: 0.006084923161306708; rouge2 std: 0.0038993930348859467; rougeL std: 0.006093324973729272
bleu mean: 0.20188119218800285
bleu std: 0.006843695514464887
S2 Question generated:
BLEU MEAN Question: 0.3558092557792962 STD Question: 0.002607279784929074
ROUGE1 MEAN Question: 0.6896426454889578 STD Question: 0.0057196970620923705
ROUGE2 MEAN Question: 0.6512054967596644 STD Question: 0.005541961314329547
ROUGEL MEAN Question: 0.6862340350234287 STD Question: 0.004371898181470405
S2 Answer generated:
BLEU MEAN Answer: 0.21950808155426996 STD Answer: 0.010947361558571149
ROUGE1 MEAN Answer: 0.5593457247207247 STD Answer: 0.008696223383870175
ROUGE2 MEAN Answer: 0.381293595674478 STD Answer: 0.009284514779417706
ROUGEL MEAN Answer: 0.5600572965572966 STD Answer: 0.009565067894733353

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.08795220000000001, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7f96578b7d90>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.4964442598163736; rouge2 mean: 0.4337931758736915; rougeL mean: 0.48424867423165413
rouge1 std: 0.022452737729980014; rouge2 std: 0.01912723835353593; rougeL std: 0.021634882780591336
bleu mean: 0.37593788048512305
bleu std: 0.024044837042366617
Answer paraphrased S1:
rouge1 mean: 0.2887209554308772; rouge2 mean: 0.1638043551507156; rougeL mean: 0.28769150273227445
rouge1 std: 0.014597842815344124; rouge2 std: 0.011442140070661307; rougeL std: 0.014602612566757562
bleu mean: 0.07428068118483072
bleu std: 0.007477267406818613

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.08795220000000001, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fd38b356d60>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.5072071345412547; rouge2 mean: 0.44029318094578573; rougeL mean: 0.4916208782709854
rouge1 std: 0.021610365229310584; rouge2 std: 0.018772956853550928; rougeL std: 0.020959008635643806
bleu mean: 0.37988183538804743
bleu std: 0.02468195352128691
Answer paraphrased S1:
rouge1 mean: 0.29779336982907834; rouge2 mean: 0.160758548358566; rougeL mean: 0.29569538182809446
rouge1 std: 0.013290696290226433; rouge2 std: 0.012197064694079341; rougeL std: 0.013597884557716607
bleu mean: 0.07962312224618563
bleu std: 0.014698458437208812

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.08795220000000001, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'pad_token_id': 50256, 'eos_token_id': 50256, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc06d4ce790>]}
EleutherAI/gpt-neo-1.3B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.4949921492435472; rouge2 mean: 0.43085929380131555; rougeL mean: 0.4808412303073359
rouge1 std: 0.016865202939453042; rouge2 std: 0.01671095933719067; rougeL std: 0.017672877839126362
bleu mean: 0.3657767080339162
bleu std: 0.028963276413569865
Answer paraphrased S1:
rouge1 mean: 0.28982132050664355; rouge2 mean: 0.155981205255154; rougeL mean: 0.28801696680126204
rouge1 std: 0.013746923092352236; rouge2 std: 0.010020880186318568; rougeL std: 0.014126320183175894
bleu mean: 0.06919000685428975
bleu std: 0.008066065748498866
S2 Question generated:
BLEU MEAN Question: 5.054512990786543e-13 STD Question: 5.450610682236472e-13
ROUGE1 MEAN Question: 0.01071093588950732 STD Question: 0.0017169454599444201
ROUGE2 MEAN Question: 0.008943115364167996 STD Question: 0.0014101050428346736
ROUGEL MEAN Question: 0.010319688481453189 STD Question: 0.0013077817337733293
S2 Answer generated:
BLEU MEAN Answer: 0.006243661556503272 STD Answer: 0.0007042447195950566
ROUGE1 MEAN Answer: 0.042489828468601686 STD Answer: 0.0037085620345940085
ROUGE2 MEAN Answer: 0.016328745809141402 STD Answer: 0.004009635456809216
ROUGEL MEAN Answer: 0.0405236925620246 STD Answer: 0.0037793897542075434

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.1393602, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc06d59a970>]}
HuggingFaceTB/SmolLM-1.7B S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.6332432002102929; rouge2 mean: 0.5528226118353756; rougeL mean: 0.6157094877399832
rouge1 std: 0.015400052112724954; rouge2 std: 0.015104014330840417; rougeL std: 0.01543620691721472
bleu mean: 0.4757562184620492
bleu std: 0.015537984411971332
Answer paraphrased S1:
rouge1 mean: 0.38781675403911575; rouge2 mean: 0.21230979421249507; rougeL mean: 0.3862288176258541
rouge1 std: 0.015713114602891074; rouge2 std: 0.013908744894703505; rougeL std: 0.015825566832326558
bleu mean: 0.13135384542788717
bleu std: 0.010826556841526107
S2 Question generated:
BLEU MEAN Question: 1.3116295563846578e-83 STD Question: 1.854924307448589e-83
ROUGE1 MEAN Question: 0.003022774327122153 STD Question: 0.002147028875475513
ROUGE2 MEAN Question: 0.0028174603174603175 STD Question: 0.001992838020553924
ROUGEL MEAN Question: 0.003022774327122153 STD Question: 0.002147028875475513
S2 Answer generated:
BLEU MEAN Answer: 0.005598703375794811 STD Answer: 0.0010683279984042627
ROUGE1 MEAN Answer: 0.039998018341594194 STD Answer: 0.002153018290170531
ROUGE2 MEAN Answer: 0.014065124489037531 STD Answer: 0.0013812756658988408
ROUGEL MEAN Answer: 0.03844331069830296 STD Answer: 0.002471534033542461

PTR Avoid lowest ppl reference ICL Experiment:
Config: {'max_new_tokens': 256, 'do_sample': True, 'temperature': 0.06338552, 'top_k': 50, 'output_scores': True, 'return_dict_in_generate': True, 'logits_processor': [<dpps.SLM.ClipLogitsProcessor object at 0x7fc067d305b0>]}
facebook/opt-1.3b S1 Experiment:
Question paraphrased S1:
rouge1 mean: 0.3037920690926861; rouge2 mean: 0.16326454397488324; rougeL mean: 0.2847573135264499
rouge1 std: 0.014324422335472636; rouge2 std: 0.012921847365575745; rougeL std: 0.014761301855720636
bleu mean: 0.08393548924769646
bleu std: 0.009418576865395517
Answer paraphrased S1:
rouge1 mean: 0.17212840592531056; rouge2 mean: 0.09158455513270834; rougeL mean: 0.17149983177180955
rouge1 std: 0.01599026168280167; rouge2 std: 0.013747106402508532; rougeL std: 0.015598761333537155
bleu mean: 0.03103001181765417
bleu std: 0.008063989814907593
S2 Question generated:
BLEU MEAN Question: 0.02003074844423517 STD Question: 0.00036091075092901936
ROUGE1 MEAN Question: 0.1075843232402719 STD Question: 0.006921187630533605
ROUGE2 MEAN Question: 0.037353218690163496 STD Question: 0.003203057289213648
ROUGEL MEAN Question: 0.09897549048908894 STD Question: 0.006999282985141317
S2 Answer generated:
BLEU MEAN Answer: 0.0137938630916248 STD Answer: 0.003208524068021915
ROUGE1 MEAN Answer: 0.09859565326745963 STD Answer: 0.011665509617886543
ROUGE2 MEAN Answer: 0.05719838699518168 STD Answer: 0.008332345822689529
ROUGEL MEAN Answer: 0.09668830508692006 STD Answer: 0.011855509486397298
